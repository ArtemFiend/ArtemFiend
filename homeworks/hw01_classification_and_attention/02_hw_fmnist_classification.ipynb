{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArtemFiend/ArtemFiend/blob/main/homeworks/hw01_classification_and_attention/02_hw_fmnist_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDsVMGiVgSq2"
      },
      "source": [
        "# Домашнее задание №1\n",
        "## Часть2: Классификация FashionMNIST\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), https://t.me/s/rads_ai\n",
        "\n",
        "В данном задании вам предстоит решить достаточно простую задачу классификации изображений с помощью сверточных нейронных сетей."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3isBRG6PgSq6"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pcJmVxGIXf47"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    predicted_labels = \",\".join([str(x.item()) for x in list(predicted_labels)])\n",
        "    return predicted_labels\n",
        "\n",
        "\n",
        "def get_accuracy(model, data_loader):\n",
        "    predicted_labels = []\n",
        "    real_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            y_predicted = model(batch[0].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "            real_labels.append(batch[1])\n",
        "\n",
        "    predicted_labels = torch.cat(predicted_labels)\n",
        "    real_labels = torch.cat(real_labels)\n",
        "    accuracy_score = (predicted_labels == real_labels).type(torch.FloatTensor).mean()\n",
        "    return accuracy_score\n",
        "\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlJBnChXXf47"
      },
      "source": [
        "Загрузите файл `hw_overfitting_data_dict.npy` (ссылка есть на странице с заданием), он понадобится для генерации посылок. Код ниже может его загрузить (но в случае возникновения ошибки скачайте и загрузите его вручную).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PNHIRtfPXf48",
        "outputId": "3000a396-90de-4418-f1e2-901464e7cfdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-10 06:59:16--  https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict [following]\n",
            "--2025-09-10 06:59:16--  https://raw.githubusercontent.com/girafe-ai/ml-course/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6272446 (6.0M) [application/octet-stream]\n",
            "Saving to: ‘hw_overfitting_data_dict.npy’\n",
            "\n",
            "hw_overfitting_data 100%[===================>]   5.98M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-09-10 06:59:16 (84.9 MB/s) - ‘hw_overfitting_data_dict.npy’ saved [6272446/6272446]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/girafe-ai/ml-course/raw/24f_ysda/homeworks/hw_overfitting/hw_overfitting_data_dict -O hw_overfitting_data_dict.npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gUsdJrvpXf48"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_overfitting_data_dict.npy\"\n",
        "), \"Please, download `hw_overfitting_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeA6Q5-CgSq7"
      },
      "source": [
        "Вернемся к задаче распознавания простых изображений, рассмотренной ранее. Но теперь будем работать с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). В данном задании воспользуемся всем датасетом целиком.\n",
        "\n",
        "__Ваша первая задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n",
        "\n",
        "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбукам с предыдущих занятий."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1Z85HeunXf49"
      },
      "outputs": [],
      "source": [
        "CUDA_DEVICE_ID = 0  # change if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nPG1KbQAgl8b"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "device = (\n",
        "    torch.device(f\"cuda:{CUDA_DEVICE_ID}\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        ")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "aYcL28OsgSq8",
        "outputId": "7ba8e795-b20f-4e2e-cc9f-3487b2a04f84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 12.4MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 211kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.93MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 12.3MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 5')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "train_fmnist_data = FashionMNIST(\n",
        "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "test_fmnist_data = FashionMNIST(\n",
        "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f\"Image label: {_label}\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6jWRv1rgSq8"
      },
      "source": [
        "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
        "\n",
        "__Внимание, ваша модель должна быть представлена именно переменной `model_task_1`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BcyEFX-RgSq8"
      },
      "outputs": [],
      "source": [
        "# Creating model instance\n",
        "class ModelTask1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ModelTask1, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1)\n",
        "    self.conv2 = nn.Conv2d(in_channels=16, out_channels=24, kernel_size=3, padding=1)\n",
        "    self.fc1 = nn.Linear(24*7*7, 128)\n",
        "    self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.max_pool2d(x, 2)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = F.max_pool2d(x, 2)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n",
        "model_task_1 = ModelTask1()\n",
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAoLV4dkoy5M"
      },
      "source": [
        "Не забудьте перенести модель на выбранный `device`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Xas9SIXDoxvZ",
        "outputId": "803b9fad-12fa-4869-94cd-85d530c752d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelTask1(\n",
              "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (fc1): Linear(in_features=1176, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "model_task_1.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pLRWysggSq9"
      },
      "source": [
        "Локальные тесты для проверки вашей модели доступны ниже:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qMQzo1ggSq9",
        "outputId": "77d92a12-4c9a-41bb-c500-923f52c63fac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model_task_1 is not None, \"Please, use `model_task_1` variable to store your model\"\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].to(device)\n",
        "    y = random_batch[1].to(device)\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model_task_1(x)\n",
        "except Exception as e:\n",
        "    print(\"Something is wrong with the model\")\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
        "\n",
        "print(\"Everything seems fine!\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suRmIPwIgSq9"
      },
      "source": [
        "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YJnU14bdnZa_",
        "outputId": "22f8bd32-f9fb-443a-e17d-5084f193e6e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 | Loss: 0.2730 | Test Accuracy: 0.8904\n",
            "Epoch 2/5 | Loss: 0.2379 | Test Accuracy: 0.8988\n",
            "Epoch 3/5 | Loss: 0.2159 | Test Accuracy: 0.9054\n",
            "Epoch 4/5 | Loss: 0.1953 | Test Accuracy: 0.9017\n",
            "Epoch 5/5 | Loss: 0.1779 | Test Accuracy: 0.9128\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "# your code here\n",
        "def train_model(model, train_loader, test_loader, epochs, lr):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        acc = get_accuracy(model, test_loader)\n",
        "\n",
        "        print(f\"Epoch {epoch}/{epochs} | Loss: {avg_loss:.4f} | Test Accuracy: {acc:.4f}\")\n",
        "\n",
        "# ============================\n",
        "# Запуск обучения\n",
        "# ============================\n",
        "train_model(model_task_1, train_data_loader, test_data_loader, epochs=5, lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zce7gt1gSq-"
      },
      "source": [
        "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usswrWYOgSq-"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Xua3TVZHgSq-",
        "outputId": "9086e639-3413-464c-d835-f2543f95f296",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on train set: 0.94083\n"
          ]
        }
      ],
      "source": [
        "train_acc_task_1 = get_accuracy(model_task_1, train_data_loader)\n",
        "print(f\"Neural network accuracy on train set: {train_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "l9KEKXBxgSq-",
        "outputId": "d17d8bec-f0fb-4fff-dc64-39d503962d26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neural network accuracy on test set: 0.9128\n"
          ]
        }
      ],
      "source": [
        "test_acc_task_1 = get_accuracy(model_task_1, test_data_loader)\n",
        "print(f\"Neural network accuracy on test set: {test_acc_task_1:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oyhmMobgSq_"
      },
      "source": [
        "Проверка, что необходимые пороги пройдены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "OAIrURCEgSq_"
      },
      "outputs": [],
      "source": [
        "assert test_acc_task_1 >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
        "assert (\n",
        "    train_acc_task_1 >= 0.905\n",
        "), \"Train accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZU2RhbNXf5A"
      },
      "source": [
        "Обращаем внимане, код ниже предполагает, что ваша модель имеет содержится в переменной `model_task_1`, а файл `hw_fmnist_data_dict.npy` находится в той же директории, что и ноутбук (он доступен в репозитории)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "UqGrbuCdXf5A",
        "outputId": "d1e26ac2-d6ef-4c5a-cd13-9419da0dd2f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Please, download `hw_fmnist_data_dict.npy` and place it in the working directory",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3382504405.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# do not change the code in the block below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# __________start of block__________\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m assert os.path.exists(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"hw_fmnist_data_dict.npy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m ), \"Please, download `hw_fmnist_data_dict.npy` and place it in the working directory\"\n",
            "\u001b[0;31mAssertionError\u001b[0m: Please, download `hw_fmnist_data_dict.npy` and place it in the working directory"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert os.path.exists(\n",
        "    \"hw_fmnist_data_dict.npy\"\n",
        "), \"Please, download `hw_fmnist_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "loaded_data_dict = np.load(\"hw_fmnist_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "submission_dict = {\n",
        "    \"train_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        "    ),\n",
        "    \"test_predictions_task_1\": get_predictions(\n",
        "        model_task_1, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        "    ),\n",
        "}\n",
        "\n",
        "with open(\"submission_dict_fmnist_task_1.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict, iofile)\n",
        "print(\"File saved to `submission_dict_fmnist_task_1.json`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gboIvMd1Xf5B"
      },
      "source": [
        "### Сдача задания\n",
        "Сдайте сгенерированный файл в соответствующую задачу в соревновании, а именно:\n",
        "    \n",
        "* `submission_dict_fmnist_task_1.json` в задачу Separation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtWnYAN_gSrA"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "21499ab2a6726e29f7050b76af0e9680227e613293d630ba279de7ebdfad9cae"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}